---
title: "5. Calculate Transmission Bottleneck"
author:
    - "Will Hannon"
date: "`r format(Sys.time(), '%d %B, %Y')`"
output: 
  html_document:
  highlight: tango
  number_sections: no
  theme: default
  toc: yes
  toc_depth: 3
  toc_float:
    collapsed: no
    smooth_scroll: yes
---

The goal of this notebook is to calculate the transmission bottleneck for the different aerosol sizes. There are two experiments, one where different sizes of impactor were used between cages and one comparing direct contact vs. aerosol contact. In the impactor experiments, each cage has 4 animal, 2 contacts and 2 donors. In the direct contact vs. aerosol contact experiment, there was a single donor used in both aerosol and direct contact conditions. I'll calculate the bottleneck assuming each possible donor/contact pair. I'll also calculate the bottleneck from the inoculate to each donor animal. Depending on the results, I'll try more stringent filters on the variants to see if this impacts the overall bottleneck size.

```{r Setup, include=FALSE}
require("knitr")
knitr::opts_chunk$set(echo = FALSE)
```

```{r Required Packages, message=FALSE, warning=FALSE}

## ==== Install Required Packages ==== ##

## List of all packages needed
packages = c("tidyverse", "rmutil", "data.table")
invisible(lapply(c(packages), library, character.only = TRUE))

```

```{r Inputs, echo=T}

## ==== File paths input data ==== ##

if (exists("snakemake")) {
  
  # Sample metadata
  sample.metadata.data = snakemake@input[[1]]
  
  # Variant calls from pysam, varscan, ivar, and lofreq
  variant.calls.data = snakemake@input[[2]]
  
  # Merged variant calls from the previous notebook 
  merged.variant.calls.data = snakemake@input[[3]]
  
  # Primer BED
  primer.bed.data = snakemake@input[[4]]

} else {

  # Sample metadata
  sample.metadata.data = "../../config/samples.csv"
  
  # Variant calls from pysam, varscan, ivar, and lofreq
  variant.calls.data = "../../results/variants/variants.csv"
  
  # Merged variant calls from the previous notebook 
  merged.variant.calls.data = "../../results/variants/merged_variants.csv"
  
  # Primer BED
  primer.bed.data = "../../results/reference/primers/primers.bed"
  
}

```

```{r Output Directory, echo=T}

figures.dir = "../../results/figures/"

```

```{r Load Data, echo=TRUE, warning=FALSE}

merged.df = read_csv(merged.variant.calls.data, show_col_types = FALSE) %>% 
  # Standardize the pair names to contact and donor
  mutate(Pair = case_when(
    Pair == 'recipient' ~ 'contact',
    TRUE ~ Pair
  ))

# Un-merged variant calls
variant.df = read_csv(variant.calls.data, show_col_types = FALSE)

# Primer positions
primer.df = fread(primer.bed.data) %>% 
  select(contig = V1,
         start = V2, 
         end = V3, 
         name = V4, 
         qual = V5, 
         direction = V6)

```

## Beta Binomial Bottleneck

To calculate the transmission bottleneck, I'll use the Approximate Beta Binomial model as described [in this paper](https://doi.org/10.1128/JVI.00171-17). I'll [adapt some code](https://github.com/weissmanlab/BB_bottleneck/blob/master/Bottleneck_size_estimation_approx.r) from the Weissman lab that implements this model.

```{r Beta Binomial Function, echo=T}

# Implement the beta binomial model as function
approx.transmission.bottleneck = function(transmission.pair.df,
                                          freq.threshold,
                                          Nb.min,
                                          Nb.max,
                                          Nb.increment,
                                          confidence.interval){
  
  # This function gives Log Likelihood for every donor recipient SNP frequency pair
  log.beta.binom = function(nu.donor, nu.contact, NB.size, freq.threshold){ 
    
      nu.donor = if_else(nu.contact <= (1 - freq.threshold), nu.donor,  1 - nu.donor)
      nu.contact = if_else(nu.contact <= (1 - freq.threshold), nu.contact,  1 - nu.contact)
      
      ll.above = 0 
      ll.below = 0 
      for(k in 0:NB.size){
        ll.above = ll.above + dbeta(nu.contact, k, (NB.size - k) ) * dbinom(k, size = NB.size, prob = nu.donor)  
        ll.below = ll.below + pbeta(freq.threshold, k, (NB.size - k)) * dbinom(k, size = NB.size, prob = nu.donor)
        } 
    
    # We use LL_val_above above the calling threshold, and LL_val_below below the calling threshold
    ll.val = if_else(nu.contact >= freq.threshold , ll.above,  ll.below )
    # Convert likelihood to log likelihood
    ll.val = log(ll.val) 
    
    return(ll.val)
  }
  
  # This function sums over all SNP frequencies in the donor and recipient
  ll.approx = function(transmission.df, freq.threshold, NB.size){  
    ll.array = log.beta.binom(transmission.df$donor, transmission.df$contact, freq.threshold, NB.size)  
    sum.ll = sum(ll.array)
    return(sum.ll)
  }

  # Filter out variants below the minimum frequency threshold in donor
  transmission.pair.df = transmission.pair.df %>% 
    filter(donor >= freq.threshold,
           donor <= 1 - freq.threshold)
  
  # Make a data frame to hold the log likelihood 
  ll.df = tibble(bottleneck_size = seq(from = Nb.min, to = Nb.max, by = Nb.increment), log_likelihood = 0) 
  
  # Calculate the log likelihood for each bottleneck size
  for(i in 1:nrow(ll.df) ){
    ll.df$log_likelihood[i] = ll.approx(transmission.pair.df, ll.df$bottleneck_size[i], freq.threshold) 
  }
  
  # Bottleneck size at which max likelihood occurs and that bottleneck
  max.ll = max(ll.df$log_likelihood)
  bottleneck.size = ll.df %>% 
  filter(log_likelihood == max.ll) %>% 
  pull(bottleneck_size)
  
  # Calculate the confidence interval
  likelihood.ratio = qchisq(confidence.interval, df = 1) 
  ci.df = filter(ll.df, 2 * (max.ll - log_likelihood) <= likelihood.ratio) 
  lower.ci.bottleneck = min(ci.df$bottleneck_size) 
  upper.ci.bottleneck = max(ci.df$bottleneck_size) 
  
  # If the confidence interval table is empty
  if (length(ci.df$log_likelihood) == 0){
    lower.ci.bottleneck = min(bottleneck.size) 
    upper.ci.bottleneck = max(bottleneck.size)
  }
  # if the bottleneck is likely larger then the max set by user
  if (max(bottleneck.size) == Nb.max){
    upper.ci.bottleneck = Nb.max
    print("Peak bottleneck value for MLE is at Nb.max! Try raising Nb.max for better bottleneck estimate.")
  }
  # if the bottleneck is likely smaller then the min set by user
  if (min(bottleneck.size) == Nb.min){
    lower_CI_bottleneck = Nb.min
    if(Nb.min > 1){
      print("Peak bottleneck value for MLE is at Nb.min! Try lowering Nb.min for better bottleneck estimate.")}
  }
  
  return(c(lower.ci.bottleneck, bottleneck.size, upper.ci.bottleneck))

}

```

## Determine Combinations

First, I'll figure out the donor contact pairs in each experiment.

```{r Donor Contact Pairs, echo=T}

# Get the donor contact pairs for each experiment
combinations.df = merged.df %>% 
  filter(Pair != "stock") %>% 
  select(Experiment, Animal, Pair) %>% 
  distinct() %>% 
  group_by(Experiment, Pair) %>%
  mutate(combination_id = row_number()) %>%
  pivot_wider(id_cols = c("Experiment", "combination_id"), 
              names_from = "Pair", values_from = "Animal") %>%
  select(-combination_id) %>%
  ungroup() %>%
  group_by(Experiment) %>%
  summarize(combinations = list(expand.grid(donor = donor, contact = contact))) %>%
  pull(combinations) %>% 
  bind_rows() %>% 
  filter(!(is.na(donor) | is.na(contact))) %>% 
  left_join(merged.df %>%
              select(Experiment, Animal) %>%
              distinct(),
            by = c("contact" = "Animal")) %>%
  
  # Remove the pairs for experiment 19 where the replicates are mismatched 
  mutate(donor_replicate = str_extract(donor, "\\d$"),
         contact_replicate = str_extract(contact, "\\d$")) %>% 
  filter(!(Experiment == 19 & (donor_replicate != contact_replicate))) %>% 
  select(!c(donor_replicate, contact_replicate)) 

```

Then, I'll determine the number of days post infection for the samples being compared. Ideally, the earliest time post contact will provide the most accurate bottleneck measurement. 

```{r Check Earliest Time}

# Add the earliest time points from each animal to the data frame
for (i in 1:nrow(combinations.df)) {
  # Get the donor and the contact 
  donor = combinations.df[i,]$donor
  contact = combinations.df[i,]$contact
  # Get the earliest day for each condition
  earliest.donor.dpc = merged.df %>% 
    filter(Animal == donor) %>% 
    pull(DPC) %>% 
    min()
  earliest.contact.dpc = merged.df %>% 
    filter(Animal == contact) %>% 
    pull(DPC) %>% 
    min()
  # Add these to the combinations
  combinations.df$donor_dpc[i] = earliest.donor.dpc
  # Add these to the combinations
  combinations.df$contact_dpc[i] = earliest.contact.dpc

}

head(combinations.df)
```

## Apply Filters

Bottleneck estimates are pretty severely effected by false-positive variants that are shared between multiple experiments. To mitigate this, I'll apply the following filters: 

1. Remove variants in primer stretches
2. Remove variants in only a single round of sequencing
3. Remove variants observed on fewer than 25 reads
4. Remove varaints identified on more than 90% of reads of the same strand orientation

```{r Filter the Merged Variants, echo=T}

# Filters on variants 
min.obsv = 25
min.bias = .9
min.freq = 0.02

# Remove the SNPs that are in primer stretches 
snps.in.primers = merged.df %>% 
  select(POS, SNP) %>% 
  left_join(., select(primer.df, c(start, end)), by = character()) %>% 
  mutate(in_primer = between(POS, start, end, incbounds = TRUE)) %>% 
  filter(in_primer) %>% 
  pull(SNP) %>% 
  unique()
  
# Remove SNPs that are only in a single round of sequencing
snps.in.both.sequencing.rounds = merged.df %>% 
  select(SNP, Sequencing_Round) %>% 
  distinct() %>% 
  group_by(SNP) %>% 
  count() %>% 
  rename(SeqRoundObsv = n) %>% 
  filter(SeqRoundObsv > 1) %>% 
  pull(SNP)

# Filter the merged data frame
filtered.merged.df = merged.df %>% 
  mutate(OBSV = ADR + ADF) %>% 
  mutate(BIAS = pmax(ADR, ADF) / OBSV) %>% 
  filter(
    OBSV >= min.obsv,
    BIAS <= min.bias,
    AF >= min.freq,
    !SNP %in% snps.in.primers,
    SNP %in% snps.in.both.sequencing.rounds
  )

```

## Calculate the Bottleneck

```{r Calculate Bottleneck, echo=T}

bottleneck.df = data.frame()
tv.df = data.frame()
for (i in 1:nrow(combinations.df)) {
  
  # Donor information
  donor = combinations.df[i,]$donor
  donor.dpc = combinations.df[i,]$donor_dpc
  donor.df = filtered.merged.df %>% 
    filter(Animal == donor, 
           DPC == donor.dpc) %>% 
    mutate(donor = AF) %>% 
    select(SNP, donor)
    
  # Contact information
  contact = combinations.df[i,]$contact
  contact.dpc = combinations.df[i,]$contact_dpc
  contact.df = filtered.merged.df %>% 
    filter(Animal == contact, 
           DPC == contact.dpc) %>% 
    mutate(contact = AF) %>% 
    select(SNP, contact)
  
  # Combine into single data frame
  transmission.pair.df = full_join(donor.df, contact.df, by = "SNP") %>% 
    mutate(donor = if_else(is.na(donor), 0, donor),
           contact = if_else(is.na(contact), 0, contact)) 
  
  # Calculate the bottleneck
  bottleneck = approx.transmission.bottleneck(transmission.pair.df,
                                 freq.threshold = min.freq,
                                 Nb.min = 1,
                                 Nb.max = 500,
                                 Nb.increment = 1,
                                 confidence.interval = .95)
  
  # Make a new bottleneck row
  bottleneck.row = list(lower_ci = bottleneck[1], 
                        upper_ci = bottleneck[3],
                        bottleneck = bottleneck[2],
                        experiment = combinations.df[i,]$Experiment,
                        donor = donor,
                        contact = contact)

  # Append the row to the bottleneck data frame 
  bottleneck.df = rbind(bottleneck.df, bottleneck.row)
  
  # Append frequencies from joined pairs for the TV plots
  transmission.pair.df$Experiment  = combinations.df[i,]$Experiment
  transmission.pair.df$Pair  = paste(donor, contact, sep = "-")
  tv.df = rbind(tv.df, transmission.pair.df)

}

```

## Variants After Filtering

What are the variants that are left over after filtering?

```{r Shared Variants, fig.width=25, fig.height=15, fig.align="center"}

# Amino acid annotations for each variant from Pysam
amino_acid_annotations = variant.df %>% 
  filter(CALLER == 'pysam') %>% 
  select(POS, REF, ALT, POS_AA, REF_AA, ALT_AA, GENE) %>% 
  mutate(SNP = paste(REF, POS, ALT, sep = "")) %>% 
  select(!c(POS, REF, ALT)) %>% 
  distinct()

# Variants fixed in the isolate
fixed.in.isolate = merged.df %>%  
  filter(Animal == "stock",
         AF >= .98) %>% 
  pull(SNP)
  
# Variants in both a donor and contact
trasmitted.snps = tv.df %>% 
  filter(donor > 0 & contact > 0,
         !SNP %in% fixed.in.isolate) %>% 
  pull(SNP) %>% 
  unique()

# Get all of the variants in the isolate
isolate.variants = variant.df %>% 
  filter(CALLER == 'pysam') %>% 
  filter(Animal == "stock") %>% 
  select(POS, REF, ALT, POS_AA, REF_AA, ALT_AA, GENE, Animal, Pair, Experiment, Condition, DPC, AF) %>% 
  mutate(SNP = paste(REF, POS, ALT, sep = "")) %>% 
  mutate(AA_Change = paste(GENE, ":", " ", REF_AA, POS_AA, ALT_AA, sep="")) %>% 
  mutate(AA_Change = case_when(
    is.na(GENE) ~ "intergenic", 
    TRUE ~ AA_Change
  )) %>% 
  mutate(Mutation = paste(SNP, " (", AA_Change , ")")) %>% 
  filter(SNP %in% trasmitted.snps)  

# Expand the merged variants data frame with variant records for every animal (including presence and absence)
expanded.merged.df = filtered.merged.df %>% 
  select(POS, REF, ALT, SNP, Animal, Pair, Experiment, Condition, DPC, AF) %>% 
  left_join(., amino_acid_annotations, by = "SNP") %>% 
  filter(SNP %in% trasmitted.snps)  %>% 
  mutate(AA_Change = paste(GENE, ":", " ", REF_AA, POS_AA, ALT_AA, sep="")) %>% 
  mutate(AA_Change = case_when(
    is.na(GENE) ~ "intergenic", 
    TRUE ~ AA_Change
  )) %>% 
  mutate(Animal_Number = if_else(str_sub(Animal, -1, - 1)   == "1", "1", "2")) %>% 
  mutate(Mutation = paste(SNP, " (", AA_Change , ")")) 
  
# Condition order 
shortened.condition.order = c("none",
                    "5 um",
                    "2 um",
                    "aerosol",
                    "direct")

# Fix the fact that the same donor was used for aerosol and direct conditions
ivc.cage.variants = expanded.merged.df %>% 
  filter(Condition == "no impactor/IVC cage") 
expanded.merged.df = expanded.merged.df %>% 
  filter(Condition != "no impactor/IVC cage") %>% 
  bind_rows(ivc.cage.variants.direct, ivc.cage.variants.aerosol) %>% 
  mutate(Condition = case_when(
    Condition == "no impactor" ~ "none",
    Condition == "5 um impactor" ~ "5 um",
    Condition == "2.5 um impactor" ~ "2 um"
  )) %>% 
  mutate(Condition = fct_relevel(as_factor(Condition), shortened.condition.order)) 

# Plot the variants
expanded.merged.df %>% 
  filter(Animal != "stock") %>% 
  mutate(Pair = if_else(Pair == "contact", "recipient", "donor")) %>% 
  ggplot(aes(x = Condition, y = AF)) +
    geom_hline(data = isolate.variants, aes(yintercept = AF), col = "#bd00ba", size = 1, linetype = "dashed") +
    geom_jitter(aes(col = Pair, group = Pair, shape = Animal_Number), na.rm=TRUE, position = position_jitterdodge(jitter.width = 0.2, dodge.width = 0.9), size = 5, alpha = 0.6) +
    facet_wrap(~fct_reorder(Mutation, POS, min)) +
    # Annotate the separation between experiments
    geom_vline(xintercept = 1.5, linetype = 2, col = "grey") + 
    geom_vline(xintercept = 2.5, linetype = 2, col = "grey") + 
    geom_vline(xintercept = 3.5, linetype = 2, col = "grey") + 
    geom_vline(xintercept = 4.5, linetype = 2, col = "grey") + 
    xlab("Condition") +
    ylab("Allele Frequency") + 
    scale_color_manual(values = c("#bd0000", "#0013bd"), name = "") +
    theme_classic()  +
      theme(legend.position="bottom", legend.box = "horizontal") +
      theme(legend.box.background = element_rect(colour = "black")) +
      theme(text=element_text(size=24,  family="Helvetica")) +
      theme(plot.title = element_text(hjust = 0.5)) +
      theme(panel.background = element_rect(fill = NA, color = "black")) +
      theme(axis.text.x = element_text(size = 18)) + 
      theme(panel.spacing = unit(2, "lines")) + 
      theme(axis.ticks.length=unit(.25, "cm")) +
      guides(shape = FALSE)

```

## Plot the Bottleneck 

Plot the bottleneck for each pair.

```{r All Bottlenecks, fig.align='center', fig.width=8, fig.height=4}

condition.order = c("no impactor",
                    "5 um impactor",
                    "2.5 um impactor")

# Get the conditions for each contact animal
conditions = merged.df %>% 
  select(Animal, Condition) %>% 
  distinct()

# Plot the Bottleneck for each pair
bottleneck.df %>% 
  left_join(., conditions, by = c("contact" = "Animal")) %>% 
  mutate(Condition = fct_relevel(as_factor(Condition), condition.order)) %>% 
  mutate(Pair = paste(donor, contact, sep = "-")) %>% 
  ggplot(aes(x = Pair, y = bottleneck, col = Condition)) + 
    geom_errorbar(aes(ymin = lower_ci, ymax = upper_ci), width = 0.2, col = "black") +
    geom_point() + 
    xlab("Donor-Recipient Pair") + 
    ylab("Bottleneck Size") + 
    theme_bw(14)  +
    theme(axis.text.x = element_text(angle = 35, hjust = 1))  +
    theme(legend.position = "bottom")

ggsave(paste(figures.dir, "supplemental-figure-4.png", sep=""), width = 8, height = 4)

```

Let's plot the mean for each bottleneck below

Because these are separate experiments, let's split this into two separate plots. 

```{r Summarized Bottleneck, fig.align='center', fig.width=8, fig.height=4, warning=F}

# Get the experiments for each condition
impactor.experiments = merged.df %>% 
  select(Condition, Experiment) %>% 
  filter(Condition %in% c('no impactor', '5 um impactor', '2.5 um impactor')) %>% 
  pull(Experiment)

# Calculate the mean bottleneck for each condition
mean.bottleneck = bottleneck.df %>% 
  left_join(., conditions, by = c("contact" = "Animal")) %>% 
  mutate(Condition = fct_relevel(as_factor(Condition), condition.order)) %>% 
  mutate(Pair = paste(donor, contact, sep = "-")) %>% 
  group_by(Condition) %>% 
  summarize(bottleneck = mean(bottleneck),
            lower_ci = min(lower_ci),
            upper_ci = max(upper_ci)) 

# Split the bottleneck data frame
impactor.bottleneck.df = bottleneck.df %>% filter(experiment %in% impactor.experiments)

# Calculate the mean bottleneck for each condition
mean.impactor.bottleneck = mean.bottleneck %>% 
  filter(Condition %in% c('no impactor', '5 um impactor', '2.5 um impactor'))

# Position of the mean bottleneck label
impactor.text.y.position = max(impactor.bottleneck.df$bottleneck) + (.1 * max(impactor.bottleneck.df$bottleneck))

# Add the conditions to the data frame and plot 
impactor.bottleneck.df %>% 
  left_join(., conditions, by = c("contact" = "Animal")) %>% 
  mutate(Condition = fct_relevel(as_factor(Condition), condition.order)) %>% 
  mutate(Pair = paste(donor, contact, sep = "-")) %>% 
  ggplot(aes(x = Condition, y = bottleneck, col = Condition)) + 
    geom_point(data = mean.impactor.bottleneck, shape=1, size = 3.5, col = "black") + 
    geom_jitter(width = 0.1, size = 1.5) + 
    geom_text(data = mean.bottleneck, aes(x = Condition, y = impactor.text.y.position, label = round(bottleneck, 2)), size = 4.5, col = "black") + 
    xlab("") + 
    ylab("Bottleneck Size") + 
    theme_bw(16)  +
    theme(legend.position = "none") +
    theme(axis.text.x = element_text(size = 12))

ggsave(paste(figures.dir, "figure-3a.png", sep=""), width = 8, height = 4)

```

## Conclusion

Generally, the conclusion of this notebook so far is that the bottleneck is narrow, but it still influenced by possible false positive variants. It's not totally clear what the impact of particle size is on the bottleneck. Generally it seems like the bottleneck isn't strongly influenced, but might be restricted by the particle size.


