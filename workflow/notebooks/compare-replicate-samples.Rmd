---
title: "3. Compare Sequencing Replicates"
author:
    - "Will Hannon"
date: "`r format(Sys.time(), '%d %B, %Y')`"
output: 
  html_document:
  highlight: tango
  number_sections: no
  theme: default
  toc: yes
  toc_depth: 3
  toc_float:
    collapsed: no
    smooth_scroll: yes
---

In this notebook, I'll look at the correlation between replicate samples. I'll see if there are any obviously problematic samples. I'll see how TCID50 and Viral Copy Number effect this, and I'll combine the replicates into a final set of variants per condition.

```{r Setup, include=FALSE}
require("knitr")
knitr::opts_chunk$set(echo = FALSE)
```

```{r Required Packages, message=FALSE, warning=FALSE}

## ==== Install Required Packages ==== ##

## List of all packages needed
packages = c("tidyverse", "UpSetR", "ggrepel")
invisible(lapply(c(packages), library, character.only = TRUE))

```

```{r Inputs, echo=T}

## ==== File paths input data ==== ##

if (exists("snakemake")) {
  
  # Sample metadata
  sample.metadata.data = snakemake@input[[3]]
  
  # Variant calls from pysam, varscan, ivar, and lofreq
  variant.calls.data = snakemake@input[[4]]
  
  
} else {

  # Sample metadata
  sample.metadata.data = "../../config/samples.csv"
  
  # Variant calls from pysam, varscan, ivar, and lofreq
  variant.calls.data = "../../results/variants/variants.csv"
  
}

```

## Compare Replicates

Let's see how the replicates compare with the heuristic filters that I determined in the previous notebook for each of the sets of variants. 

```{r Load Variants, echo=TRUE, warning=FALSE, message=FALSE}

variant.df = read_csv(variant.calls.data, show_col_types = FALSE) %>% 
    mutate(SNP = paste(REF, POS, ALT, sep = "")) 

min.freq = 0.02
min.depth = 200
min.obsv = min.depth * min.freq

variants.filtered.df = variant.df %>% 
  filter(
    AF >= min.freq,
    DP >= min.depth,
    ADF + ADR >= min.obsv
    )

```

The filters that I'm using are a minimum allele frequency of `r min.freq`, a minimum depth of `r min.depth`, a minimum number of variants reads of `r min.obsv`.

```{r Pivot Replicates, echo=T}

replicate.filtered.df = variants.filtered.df %>%
  # Remove the isolate that isn't sequenced in duplicate. 
  filter(Run != "HL-2162") %>% 
  # Unique run condition
  mutate(Identifier = paste(Animal, DPI, sep="_"),
         Replicate = paste("Replicate", Replicate, sep="_")
         ) %>% 
  select(POS, REF, ALT, AF, CALLER, Identifier, Replicate) %>% 
  # Pivot wider on the replicate
  pivot_wider(names_from = Replicate, values_from = AF, values_fill = 0)  
    

```

Let's see what this looks like for all variants, samples and callers at once. 

```{r Plot All Callers Filter, fig.align='center', fig.width=6, fig.height=6}

replicate.filtered.df %>% 
  ggplot(aes(x = Replicate_1, y = Replicate_2)) + 
    geom_point() + 
    xlab("Replicate 1") +
    ylab("Repcliate 2") + 
    facet_wrap(~CALLER) + 
    theme_bw()

```

For the most part, the correlation between replicates is really good regardless of the variant calling approach. There are however some variants that are fairly high frequency missed by one replicate or the other. Could this be due to the filters that I'm using? To test this, I'll see what the correlation looks like without any filters. 

```{r Plot All Callers no Filter, fig.align='center', fig.width=6, fig.height=6}

replicates.unfiltered.df = variant.df %>%
  # Remove the isolate that isn't sequenced in duplicate. 
  filter(Run != "HL-2162") %>% 
  # Unique run condition
  mutate(Identifier = paste(Animal, DPI, sep="_"),
         Replicate = paste("Replicate", Replicate, sep="_")
         ) %>% 
  select(POS, REF, ALT, AF, CALLER, Identifier, Replicate) %>% 
  # Pivot wider on the replicate
  pivot_wider(names_from = Replicate, values_from = AF, values_fill = 0) 

replicates.unfiltered.df %>% 
  ggplot(aes(x = Replicate_1, y = Replicate_2)) + 
    geom_point() + 
    xlab("Replicate 1") +
    ylab("Repcliate 2") + 
    facet_wrap(~CALLER) + 
    theme_bw()

```

This fixes (for the most part) the high frequency variants that are missing between replicates. We know that these are unlikely to be false positives and we should avoid skewing the consensus of the samples with filters that are too stringent. 

One solution is to merge the replicates **without** filters, then use the depth, frequency, and observation filters on the merged data to remove possible artifacts. 

To merge replicates, I'll take the allele frequency and depth measurements from the more highly covered replicate. 

```{r Merge Replicates, echo=T}

merged.variants.df = variant.df %>%
  # Remove the isolate that isn't sequenced in duplicate. 
  filter(Run != "HL-2162") %>% 
  # Pivot wider on the replicate
  pivot_wider(id_cols=c(POS, REF, ALT, SNP, CALLER, Animal,
                        Pair, Experiment, Condition, DPI, DPC,
                        TCID50, RNA_Copies, Sequencing_Round),
              names_from = Replicate,
              values_from = c(AF, DP, ADF, ADR),
              names_prefix = "Replicate_") %>% 
  # Filter out variants called by a single replicate
  filter(!(is.na(AF_Replicate_1) | is.na(AF_Replicate_2))) %>% 
  # Collapse into a single set of variants 
  mutate(
    AF = if_else(DP_Replicate_1 >= DP_Replicate_2, AF_Replicate_1, AF_Replicate_2),
    ADF = if_else(DP_Replicate_1 >= DP_Replicate_2, ADF_Replicate_1, ADF_Replicate_2),
    ADR = if_else(DP_Replicate_1 >= DP_Replicate_2, ADR_Replicate_1, ADR_Replicate_2),
    DP = if_else(DP_Replicate_1 >= DP_Replicate_2, DP_Replicate_1, DP_Replicate_2)
  ) %>% 
  select(!(ends_with('Replicate_1') | ends_with('Replicate_2'))) %>% 
  # Finally, apply the heuristic filters 
  filter(
    AF >= min.freq,
    DP >= min.depth,
    ADF + ADR >= min.obsv
  ) 

```

Finally, we need to decide how to combine the variants from the various callers. Let's look at the Venn diagram of the callers after filtering and merging. 

```{r Merged Caller UpSet, echo=T, fig.align='center', fig.width=6, fig.height=3}

merged.variants.df %>% 
  select(Animal, DPI, SNP, CALLER) %>% 
  mutate(SNP_ID = paste(Animal, DPI, SNP, sep = "-")) %>% 
  select(SNP_ID, CALLER) %>% 
  distinct() %>% 
  mutate(Tally = 1) %>% 
  pivot_wider(names_from = "CALLER", values_from = "Tally", values_fill = 0) %>% 
  as.data.frame(row.names = SNP_ID) %>%
  upset(., 
        sets = c("lofreq", "varscan", "ivar", "pysam"),
        sets.bar.color = "#56B4E9",
        order.by = "freq",
        empty.intersections = "on",
        text.scale = 1.5)

```

To choose a final set of variants, I'm going to select the variants called by two or more callers (if one of those callers included the `pysam` approach). Then, I'm going to get the quantitative metrics from `pysam`. 

```{r Combine Callers, echo=T}

# Get the isolate mutations that pass the filters
isolate.rows = variant.df %>%
  # Select on the isolate
  filter(Run == "HL-2162") %>% 
  # Change DPI to 0
  mutate(DPI = 0, DPC = -1) %>% 
  # Apply the heuristic filters 
  filter(
    AF >= min.freq,
    DP >= min.depth,
    ADF + ADR >= min.obsv
  ) %>% 
  select(colnames(merged.variants.df))

# Get the IDs for variants in 2+ callers if one was Pysam
selected.variant.ids = merged.variants.df %>% 
  bind_rows(isolate.rows) %>% 
  select(Animal, DPI, SNP, CALLER) %>% 
  mutate(SNP_ID = paste(Animal, DPI, SNP, sep = "-")) %>% 
  select(SNP_ID, CALLER) %>% 
  distinct() %>% 
  mutate(Tally = 1) %>% 
  pivot_wider(names_from = "CALLER", values_from = "Tally", values_fill = 0) %>% 
  filter((pysam + ivar + varscan) >= 2) %>% 
  pull(SNP_ID)

# Finally, filter the merged variants
filtered.merged.variants.df = merged.variants.df %>% 
  bind_rows(isolate.rows) %>% 
  mutate(SNP_ID = paste(Animal, DPI, SNP, sep = "-")) %>% 
  filter(SNP_ID %in% selected.variant.ids) %>% 
  filter(CALLER == 'pysam') %>% 
  select(!c(SNP_ID, CALLER))

```

These filters and merges leave us with a final set of `r nrow(filtered.merged.variants.df)` variants across the `r nrow(distinct(select(filtered.merged.variants.df, Animal, DPI)))` conditions.

Let's write these out to a file. 

```{r Write out Variants}

write_csv(filtered.merged.variants.df, "../../results/variants/merged_variants.csv")

```

## Problematic samples

Although I've keep all samples in the variant data frame up to this point, it's important to know if any individual samples might be problematic - i.e. due to low coverage. One way to check this is to look at how much the variants called between replicates deviate from one another. I'll investigate this below, highlighting any samples to look out for in the future. 

I'll start by summarizing the variance between replicates in a given sample. One super trivial approach that weights higher frequency alleles is to take the average difference in frequency between replicates. I'll do that below. 

```{r Average AF Difference v. RNA Copies, fig.align='center', fig.width=3, fig.height=3}

variant.df %>%
  # Remove the isolate that isn't sequenced in duplicate. 
  filter(Run != "HL-2162") %>% 
  # Pivot wider on the replicate
  pivot_wider(id_cols=c(POS, REF, ALT, SNP, CALLER, Animal,
                        Pair, Experiment, Condition, DPI, DPC,
                        TCID50, RNA_Copies, Sequencing_Round),
              names_from = Replicate,
              values_from = c(AF),
              names_prefix = "Replicate_", 
              values_fill = 0) %>% 
  # Calculate the mean difference 
  mutate(Delta_AF = abs(Replicate_1 - Replicate_2)) %>% 
  group_by(Animal, Experiment, Condition, DPI, TCID50, RNA_Copies) %>% 
  summarize(Mean_Delta_AF = mean(Delta_AF)) %>% 
  ungroup() %>% 
  mutate(Label= paste(Animal, " ", DPI, "-DPI", sep="")) %>% 
  # Plot the difference
  ggplot(aes(x = RNA_Copies, y = Mean_Delta_AF, label = Label, col = DPI)) + 
    geom_point() + 
    geom_text_repel(size = 2) + 
    xlab("Viral RNA Copies") + 
    ylab("Mean Allele Frequency Difference") + 
    theme_bw() + 
    theme(legend.position = "none")
  

```



